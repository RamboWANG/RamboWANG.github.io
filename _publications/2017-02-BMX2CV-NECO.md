---
title: "Block-regularized mx2 cross-validated estimator of the generalization error"
collection: publications
permalink: /publication/2017-02-BMX2CV-NECO
excerpt: 'A cross-validation method based on m replications of two-fold cross validation is called an mx2 cross validation. An mx2 cross validation is used in estimating the generalization error and comparing of algorithms’ performance in machine learning. However, the variance of the estimator of the generalization error in mx2 cross validation is easily affected by random partitions. Poor data partitioning may cause a large fluctuation in the number of overlapping samples between any two training (test) sets in mx2 cross validation. This fluctuation results in a large variance in the mx2 cross-validated estimator. The influence of the random partitions on variance becomes serious as m increases. Thus, in this study, the partitions with a restricted number of overlapping samples between any two training (test) sets are defined as a block-regularized partition set. The corresponding cross validation is called block-regularized mx2 cross validation (mx2 BCV). It can effectively reduce the influence of random partitions. We prove that the variance of the mx2 BCV estimator of the generalization error is smaller than the variance of mx2 cross-validated estimator and reaches the minimum in a special situation. An analytical expression of the variance can also be derived in this special situation. This conclusion is validated through simulation experiments. Furthermore, a practical construction method of mx2 BCV by a two-level orthogonal array is provided. Finally, a conservative estimator is proposed for the variance of estimator of the generalization error.'
date: 2017-01-19
venue: 'Neural Computation'
paperurl: 'https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00923'
citation: 'Ruibo Wang, Yu Wang, Jihong Li, Xingli Yang and Jing Yang. (2017). &quot;Block-regularized mx2 cross-validated estimator of the generalization error.&quot; <i>Neural Computation</i>. 29(2).'
---
A cross-validation method based on m replications of two-fold cross validation is called an mx2 cross validation. An mx2 cross validation is used in estimating the generalization error and comparing of algorithms’ performance in machine learning. However, the variance of the estimator of the generalization error in mx2 cross validation is easily affected by random partitions. Poor data partitioning may cause a large fluctuation in the number of overlapping samples between any two training (test) sets in mx2 cross validation. This fluctuation results in a large variance in the mx2 cross-validated estimator. The influence of the random partitions on variance becomes serious as m increases. Thus, in this study, the partitions with a restricted number of overlapping samples between any two training (test) sets are defined as a block-regularized partition set. The corresponding cross validation is called block-regularized mx2 cross validation (mx2 BCV). It can effectively reduce the influence of random partitions. We prove that the variance of the mx2 BCV estimator of the generalization error is smaller than the variance of mx2 cross-validated estimator and reaches the minimum in a special situation. An analytical expression of the variance can also be derived in this special situation. This conclusion is validated through simulation experiments. Furthermore, a practical construction method of mx2 BCV by a two-level orthogonal array is provided. Finally, a conservative estimator is proposed for the variance of estimator of the generalization error.

[Download paper here](https://doi.org/10.1162/NECO_a_00923)

Recommended citation: Ruibo Wang, Yu Wang, Jihong Li, Xingli Yang and Jing Yang. (2017). "Block-regularized mx2 cross-validated estimator of the generalization error." <i>Neural Computation</i>. 29(2).